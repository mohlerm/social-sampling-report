Polling is a widely used method to achieve a public opinion on a certain subject gained from a sample. For example, one could think of polls before \textit{Bundesrat} elections to estimate the outcome or polls to receive students' opinions on their visited lectures.
Following the first example, pollsters would like to ask only a subset of the population while still getting significant results which party might win the vote. This is commonly known as sampling.
The two fundamental quantities of interest in sampling are \textit{number of samples} (how many citizens to ask) and the \textit{error rate} (error caused by observing a sample instead of the whole voters). As shown in chapter ref{algorithms}, if we wish to approximate a fraction within an additive error of $\epsilon$, $O(1/\epsilon^{2})$ samples are both necessary and sufficient.

In practice we want to have a low error but still only require as few samples as possible.
Since the sampling costs are usually a significant burden, research has proposed several alternatives to reduce the sample size.
For instance instead of sampling uniformly one could choose its samples with a built in bias.
However this method is vulnerable to introduce a so called \textit{systematic bias} which can lead to systematic errors in the outcome.

Another, recently popular approach is to use \textit{expectation polling}, where voters are asked about their expected outcome of the poll. This stands in contrast to the classical \textit{intent polling}, where voters are asked about their polling intent. David Rothschild and Justin Wolvers explored the value of expectation polling in a paper published 2009 \cite{rothschild2009forecasting}. Considering the focus of press and pollsters on intent polling they call it conventional wisdom that results obtained by intent polling are more accurate. Nonetheless, executed on the example of Presidential Electoral College races they provide robust evidence that expectation based polling yields to more accurate predictions of election outcomes.
Unfortunately they fall short on providing any theoretical guarantees on either the sampling bias or sampling error.

In this report, influenced by the ideas of of expectation polling, I present a method called \textit{social sampling}, suggested and described by Anirban Dasgupta, Ravi Kumar and D Sivakumar in \cite{dasgupta2012social}.
Their idea is to reduce the sampling size by asking a member of a social network considering they will be able to summarize their friends opinions when asked the right questions.
Even though this means that the actual structure of the network plays a role when analyzing the error, they assume a saving in number of samples by a factor of around \textit{d}, the average amount of friends of a member in a social network.

What follows is a formal introduction to a group of estimators I call \textit{samplers} as well as four concrete instances of these type of estimators taken from Dasguptas paper \cite{dasgupta2012social}. I analyze sampling bias and provide theoretical relations between sample size and sampling error including some proofs.
I will also provide precise characterizations on errors and how they behave applied to large, real-world networks on the basis of Dasguptas work.
