Polling is a widely used method to achieve a public opinion on a certain subject gained from a sample. For example, one could think of polls before \textit{Bundesrat} elections to estimate the outcome or polls to receive student's opinions on their visited lectures.
Following the first example, pollers would like to ask only a subset of the population while still get significant results which party might win the vote. This is commonly known as sampling.
The two fundamental quantities of interest in polling are \textit{number of samples} (how many citizens to ask) and the \textit{error rate} (error caused by observing a sample instead of the whole voters). They are related in a way, that if we wish to approximate a fraction within an additive error of $\epsilon$, $O(1/\epsilon^{2})$ samples are both necessary and sufficient.

In practice we want to have a low error but still only require as little samples as possible.
Since the sampling costs are usually a significant burden, research has proposed several alternatives to reduce the sample size.
For instance instead of sampling uniformly one could choose their samples with a built in bias.
However this method is vulnerable to introduce a so called \textit{systematic bias} which can lead to systematic errors in the outcome.

Another, recently popular approach is to use \textit{expectation polling}, where voters are asked about their expectation about the outcome of the poll. This stands in contrast to the classical \textit{intent polling}, where voters are asked about their polling intent. In \cite{rothschild2009forecasting} David Rothschild and Justin Wolvers explored the value of expectation polling. Considering the focus of press and pollsters on intent polling they call it conventional wisdom that these type of polls are more accurate. However, executed on the example of Presidential Electoral College races they provide robust evidence that expectation based polling yields to more accurate predictions of election outcomes.
Unfortunately they fall short on providing any theoretical guarantees on either the sampling bias or sampling error.

In this paper, influenced by the ideas of of expectation polling, we present a set method called \textit{social sampling}, suggested and described by Anirban Dasgupta, Ravi Kumar and D Sivakumar in \cite{dasgupta2012social}.
Their idea is to reduce the sampling size by asking a member of a social network considering they will be able to summarize their friends opinions when asked the right questions.
Even though this means that the actual structure of the network plays a role when analyzing the error, they assume a saving in number of samples by a factor of around \textit{d}, the average amount of friends of a member in a social network.

What follows is a formal introduction to a group of estimators we call \textit{samplers} as well as concrete instances of these type of estimators. We analyze sampling bias and provide theoretical relations between sample size and sampling error including some proofs.
We will also provide precise characterizations on errors and how they behave applied to large, real-world networks.
